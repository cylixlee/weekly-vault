# 对抗训练中神经网络的良性过拟合

<small style="color: gray; font-family: 'IBM Plex Sans SC Medium'">2025/02/17 · 周论文阅读 · 李政翱</small>

> **来源**
> 
> 此论文收录于 ICML 2024，原文为[Benign Overfitting in Adversarial Training of Neural Networks](https://openreview.net/forum?id=DyvhD8J3Wl).

本研究针对对抗训练中两层神经网络的良性过拟合现象展开理论分析。在含标签噪声的混合分布假设下，首次证明了**对抗训练能够使鲁棒训练损失趋近于零**，**同时实现干净测试误差与鲁棒测试误差的双重优化**。特别地，当 $\mathcal l_2$ 范数扰动预算处于适中范围时，鲁棒测试误差可逼近标签噪声率。理论结果通过合成数据和 MNIST 数据集实验得到验证，揭示了维度、信号强度与扰动预算之间的定量关系。

## 引言

传统机器学习理论认为过拟合会损害模型泛化能力，但深度神经网络展现出“良性过拟合”的特殊现象。对抗样本的发现揭示了深度模型的脆弱性，而对抗训练作为主要防御手段，其训练动态与泛化特性仍存在理论空白。现有研究观察到对抗训练中存在“鲁棒过拟合”现象，但对其是否具备良性过拟合特性尚未明确。本文首次从理论层面证明对抗训练神经网络可以实现良性过拟合，建立了鲁棒训练损失的收敛性保证和测试误差的泛化边界，为理解对抗训练的泛化机制提供了新的理论视角。

## 相关工作

已有研究在多个领域探讨了良性过拟合现象。线性模型和核方法的理论分析表明，*特定条件下模型可在过拟合训练数据的同时保持良好泛化性能*。卷积网络的相关研究进一步扩展到非平滑激活函数场景。在对抗训练领域，现有工作主要关注经验性缓解方法（如早停、正则化）和基于复杂度理论的泛化保证，但传统分析方法难以解释对抗训练中的良性过拟合现象。近期关于线性模型对抗训练闭式解的研究为本文提供了理论基础，但神经网络的分析仍受限于 NTK 框架或强分布假设。

## 方法框架

研究采用混合分布生成数据样本，核心信号分量满足
$$x_c = y_c\mu + \xi$$
其中噪声项 $\xi$ 服从强对数凹分布，标签噪声通过总变差距离约束建模。

模型选用两层神经网络架构
$$f(x;W)=\frac{1}{\sqrt{m}}\sum a_sφ(⟨w_s,x⟩)$$
采用对称初始化策略，顶层权重固定为 $\pm 1$ 以避免参数冗余。

对抗训练算法基于梯度下降优化鲁棒损失函数
$$\ell_{rob}(W) = \mathbb{E}\max_{\tilde{x}∈B_2(x,α)} ℓ(yf(\tilde{x};W))$$
关键假设包括高维数据条件（$d ≥ C\max(||μ||^2n, n^2(\log(n/δ)+α^2))$）、小噪声率约束（$β ∈ [0,1/C]$）以及适中的初始化范围和步长设置。

## 理论发现

主要定理揭示了对抗训练的动态特性与泛化规律。**对于平滑和非平滑激活函数，研究证明经过对抗训练的神经网络能够实现鲁棒训练损失任意接近零，同时训练错误率完全消失**。在泛化性能方面，干净测试误差上界由标签噪声率与指数衰减项共同决定，而鲁棒测试误差在扰动预算满足$α/||μ|| ≤ \sqrt{n||μ||²/d}/C$ 时同样逼近噪声率。特别地，当扰动强度超过信号范数（$α ≥ ||μ||$）时，鲁棒测试误差将退化至随机猜测水平。这些结果与高斯分布下的最优风险理论相吻合，揭示了数据维度、样本规模与信号强度之间的复杂交互关系。

理论分析表明，**对抗训练的动态轨迹在小扰动场景下与干净训练保持近似，但随着扰动增强逐渐偏离**。这种现象解释了对抗训练需要更多数据支持鲁棒泛化的经验观察（Schmidt et al., 2018），同时为设计高效对抗训练算法提供了理论依据。

## 实验验证

合成数据实验采用规范参数设置：信号向量 $μ$ 沿标准基方向，标签噪声率 $\beta=0.1$，噪声服从高斯分布。实验结果清晰呈现相位转变现象：干净分类精度在 $d=O(||μ||^4)$ 时达到最优，而鲁棒精度需要更强的维度约束 $d=O(||μ||^2)$ 。训练损失曲线显示对抗训练成功驱动损失趋零，测试误差收敛至噪声率水平。参数敏感性分析表明，维度增加、信号强度减弱或扰动预算扩大均会导致性能下降，与理论预测高度一致。

![[Benign Overfitting Clean Test.png|center|300]]

![[Benign Overfitting Extended.png|center|512]]

在 MNIST 数据集上的扩展实验发现，尽管真实数据分布不严格满足理论假设，但仍可观察到类似的相位转变趋势。对抗训练过程中，鲁棒训练损失与测试误差呈现同步下降，验证了理论框架的实际指导价值。特别值得注意的是，当输入数据经过标准化预处理后，实验现象与合成数据结果展现出更强的相似性，这为理解真实场景下的对抗训练提供了新的视角。

## 结论与展望

本研究首次从理论上证明对抗训练神经网络可以实现良性过拟合，建立了包含收敛性保证和泛化边界的完整理论体系。研究结果揭示了数据维度、信号强度与扰动预算之间的定量关系，为设计高效对抗训练算法提供了理论指导。未来研究方向包括：扩展理论框架至更一般的数据分布，研究维度与样本量同阶时的泛化特性，探索中等扰动强度下的理论保证，以及建立真实数据集的理论解释模型。这些进展将有助于深化对深度学习鲁棒性的本质理解，推动安全可靠的机器学习系统发展。