# 迈向对抗样本鲁棒的深度学习模型

> **来源**
> 
> 本文是经典的对抗样本相关论文，提出了*对抗训练* 方法。原文为 [Towards Deep Learning Models Resistant to Adversarial Attacks](https://openreview.net/forum?id=rJzIBfZAb)，收录于 ICLR 2018。

本文使用自然鞍点（min-max）公式描述对抗攻击中的安全概念。这一公式使我们能够将攻击和防御转换到一个共同的理论框架中，自然地封装了大多数之前关于对抗样本的工作。本文的主要贡献如下：

1. 本文**对鞍点公式对应的优化场景进行了仔细研究**。虽然该问题的组成部分具有非凸非凹性，但该问题是可处理的。此外，还得出 PGD 方法是利用了网络局部一阶信息的最强攻击方法。
2. 探讨了**网络架构对于对抗性鲁棒性的影响**，并发现模型容量在这里起着重要的作用。为了可靠地抵御强大的对抗攻击，网络需要比只正确分类良性例子更大的容量。
3. 基于上述见解，本文在 MNIST 和 CIFAR10 数据集上**训练网络**，这些网络对广泛的对抗性攻击具有鲁棒性。

总的来说，这些发现表明，安全的神经网络是触手可及的。

## 对抗鲁棒性的优化视角

### 经验风险最小化（ERM）框架

考虑一个标准分类任务：

- 数据分布 $\mathcal D$ 由多对输入 $x \in \mathbb R^d$ 及其标签 $y \in [k]$ 组成；
- 假设给定了一个恰当的损失函数 $L(\theta,x,y)$ ，比如交叉熵损失；
- 模型参数使用 $\theta \in \mathbb R^p$ 表示。

模型的训练目标即为寻找模型参数 $\theta$ 使得**期望风险** $\mathbb E_{(x,y) \sim D}\left[L(x,y,\theta)\right]$ 最小。

> **期望风险**
> 
> 期望风险的核心含义是模型参数 $\theta$ 在自然数据分布 $\mathcal D$ 上的平均损失，也即模型在未受干扰的干净数据上的性能表现。从*优化* 的角度来看，模型在训练时并不直接根据“正确率”来调整参数，而是根据损失来修正误差。

以上的定义称作**经验风险最小化**框架（Empirical risk minimization, ERM）。这是机器学习中的一种核心优化框架。然而，这种经典的框架并不能产生对抗鲁棒的模型。形式上来说，存在很多对抗攻击方法以属于 $c_1$ 类别的样本 $x$ 作为输入，并找到样本 $x^{adv}$，使得 $x^{adv}$ 与 $x$ 相当接近，但让模型误分类为 $c_2 \ne c_1$ 类别。

### 增强的 ERM 框架

为了可靠地训练对抗鲁棒的模型，需要对传统的 ERM 模型进行增强。首先需要定义对抗攻击：对于每个数据点 $x$，引入一系列允许的扰动 $\mathcal S \subseteq \mathbb R^d$ 作为对抗攻击的形式化操作能力。

接下来，使用以上定义的攻击来更改原有的 ERM 公式：
$$
\min_{\theta} \rho(\theta), \quad \text{where}\ \rho(\theta)=\mathbb E_{(x,y)\sim\mathcal D}\left[\max_{\delta\in\mathcal S}L(\theta,x+\delta,y)\right]
$$
作为本文主要研究的公式。这个公式给予了一个统一的视角，包含了许多之前关于对抗鲁棒性的工作成果。本文的观点源于将鞍点问题看作是一个内部最大化问题和一个外部最小化问题的组成部分。这两个问题在我们的语境中都有一个很自然的解释：、

- **内部最大化**问题的目的是找到一个给定的数据点 $x$ 的对抗版本 $x^{adv}$ 。这正是攻击一个给定的神经网络的问题。
- **外部最小化**问题的目标是找到模型参数，使得内攻击问题给出的“对抗损失”最小化。

这正是使用对抗训练技术来训练鲁棒分类器的问题。

## 迈向普遍鲁棒的网络

根据增强的 ERM 公式，对抗损失 $\rho(\theta)$ 足够小时保证允许的攻击方法无法欺骗网络。因此，如何求得上述公式的解是本文的主要关注点。

不幸的是，我们无法知道合理时间内是否能求得该方程的良好的解。解决鞍点问题涉及到解决**非凸外最小化问题**和**非凹内最大化问题**。本文的关键贡献之一是证明了，在实践中，人们确实可以解决鞍点问题。
